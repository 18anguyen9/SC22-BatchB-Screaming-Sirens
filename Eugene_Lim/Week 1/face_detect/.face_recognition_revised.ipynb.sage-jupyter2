{"backend_state":"init","connection_file":"/projects/375a9615-5617-48b6-a132-fe9d08f3c36b/.local/share/jupyter/runtime/kernel-19815169-e12c-4034-857f-98c8c1e70e3b.json","kernel":"cv_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"colab":{"collapsed_sections":[],"name":"aicamp_face_recognition.ipynb","provenance":[]}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1656535430034,"exec_count":8,"id":"783795","input":"#import dependencies\nimport cv2\nfrom skimage import io\nimport matplotlib.pyplot as plt","kernel":"cv_env","metadata":{"id":"MvO5PwWjmXDl","vscode":{"languageId":"python"}},"pos":3,"start":1656535430025,"state":"done","type":"cell"}
{"cell_type":"code","end":1656535433321,"exec_count":9,"id":"8fe721","input":"#get the cascade classifier from the cv2 filepath\nfaceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n\n#url of the image\nurl = \"https://image.shutterstock.com/image-photo/young-successful-team-four-business-260nw-289449125.jpg\"","kernel":"cv_env","metadata":{"id":"3AeOvLI76slQ","vscode":{"languageId":"python"}},"pos":4,"start":1656535433298,"state":"done","type":"cell"}
{"cell_type":"code","end":1656535462010,"exec_count":10,"id":"5f2633","input":"#read the picture from the url and turn it to BGR format\npicture = io.imread(url)\n\n#convert picture to grayscale\ngray = cv2.cvtColor(picture, cv2.COLOR_RGB2GRAY)","kernel":"cv_env","metadata":{"id":"rvtpyzf48e_r","vscode":{"languageId":"python"}},"pos":6,"start":1656535461964,"state":"done","type":"cell"}
{"cell_type":"code","end":1656535463865,"exec_count":11,"id":"b4706d","input":"plt.axis(\"off\")\nplt.imshow(picture)\nplt.show()","kernel":"cv_env","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"Dr_8wri_5Y_z","outputId":"03a9bca6-f0f9-4208-963f-e2aca56329ad","vscode":{"languageId":"python"}},"output":{"0":{"data":{"image/png":"b82f3569b7b0ed6b8b5fd85cc4ada1b234f73775","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":8,"start":1656535463707,"state":"done","type":"cell"}
{"cell_type":"code","end":1656535465000,"exec_count":12,"id":"437d40","input":"plt.axis(\"off\")\nplt.imshow(gray, cmap=\"gray\")\nplt.show()","kernel":"cv_env","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"DiclYgTz5gXN","outputId":"6d26173c-3062-48a6-dadf-2814787c3130","vscode":{"languageId":"python"}},"output":{"0":{"data":{"image/png":"ed54dd3b23ed827cf125f84c001020a6ca0db3db","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":9,"start":1656535464904,"state":"done","type":"cell"}
{"cell_type":"code","end":1656535467129,"exec_count":14,"id":"b0babb","input":"# Detect faces in the image\nfaces = faceCascade.detectMultiScale(\n    gray,\n    scaleFactor=1.1,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n)","kernel":"cv_env","metadata":{"id":"qOH1m1Z69J9h","vscode":{"languageId":"python"}},"pos":11,"start":1656535467073,"state":"done","type":"cell"}
{"cell_type":"code","end":1656535932048,"exec_count":25,"id":"76f915","input":"# Your code here\nimport cv2\nfrom skimage import io\nimport matplotlib.pyplot as plt\n\nfaceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n\nx = \"scientists.jpg\"\npic = io.imread(x)\n\ngray = cv2.cvtColor(pic, cv2.COLOR_RGB2GRAY)\n\nplt.axis(\"off\")\nplt.imshow(pic)\nplt.show()\n\nplt.axis(\"off\")\nplt.imshow(gray, cmap=\"gray\")\nplt.show()\n\n\nfaces = faceCascade.detectMultiScale(\n    gray,\n    scaleFactor=1.1,\n    minNeighbors=5,\n    minSize=(30, 30),\n    flags = cv2.CASCADE_SCALE_IMAGE\n)\n\n\n#print the number of faces found\nprint(f\"Found {len(faces)} faces!\")\n\n# Draw a rectangle around the faces\nfor (x, y, w, h) in faces:\n    cv2.rectangle(pic, (x, y), (x+w, y+h), (0, 255, 0), 2)\n\n#show the image with the rectangle drawn around it\nplt.axis(\"off\")\nplt.imshow(pic)\nplt.show()","kernel":"cv_env","metadata":{"vscode":{"languageId":"python"}},"output":{"0":{"data":{"image/png":"84999baa81d5f2458f5816bd7b9c61e9b3a62a56","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}},"1":{"data":{"image/png":"6ea54e16152e47f6e69ce244e1ef558d820cfc19","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}},"2":{"name":"stdout","text":"Found 3 faces!\n"},"3":{"data":{"image/png":"6fe33aeaba4e266ccccebc4e7077f373f34cb3cc","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":16,"start":1656535931538,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":22,"id":"aa116b","input":"#print the number of faces found\nprint(f\"Found {len(faces)} faces!\")\n\n# Draw a rectangle around the faces\nfor (x, y, w, h) in faces:\n    cv2.rectangle(picture, (x, y), (x+w, y+h), (0, 255, 0), 2)\n\n#show the image with the rectangle drawn around it\nplt.axis(\"off\")\nplt.imshow(picture)\nplt.show()\n\n","kernel":"cv_env","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"Vx2rUAOH9N6p","outputId":"8e0c08b1-d83d-4bfe-bdff-cc4887bc32fb","vscode":{"languageId":"python"}},"output":{"0":{"name":"stdout","text":"Found 4 faces!\n"},"1":{"data":{"image/png":"ff7b491786c0f84a9c70fb2f0682bc4746125318","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}},"2":{"data":{"image/png":"6ea54e16152e47f6e69ce244e1ef558d820cfc19","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":13,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"176781","input":"### Display the Results\n\nThe display will first output the length of the list of faces, or the number of faces, to the user. Then, for each of the face coordinates, cv2 will draw a green rectangle around the faces. Finally cv2_imshow function will display the main image with the rectangles drawn on top.","metadata":{"id":"g6MqDa0P9MVz"},"pos":12,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"60b8a5","input":"### Dependencies\n\nFirst we will import the dependencies, or libraries, necessary for this project. The dependencies are OpenCV for the face detector, skimage for reading an image from a url, and pyplot for displaying the image in this notebook.","metadata":{"id":"6QPj94nu6zrE"},"pos":1,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"64e472","input":"### Detect the Faces\n\nWe execute the detectMultiScale method to detect the faces. \n\n* The first input is the **grayscale image** we want to use for detection. \n\n* **scaleFactor** is used if the image is too large and we make it smaller by a factor of 1.1 as the face detector can only detect faces in a certain range of sizes.\n \n* **minNeighbors** is one of the most important parameters in the model. Remember, the image is first split into many small sections before classification. If minNeighbors is 5, there must be 5 other parts, or sections, of a face around a certain section if that section can be classified as part of a face (because usually one part of the face is surrounded by other parts). If you make minNeighbors larger, than the model will be much more sure about the faces it detects but it might miss some faces. If you make this smaller, the model will detect more faces but it will also make more mistakes. \n\n* **minSize** is the minimum size a face must be in order for it to be viable for detection.  \n\nThe method will output the coordinates of all the faces found.\n\n","metadata":{"id":"FcClRtog9Fpf"},"pos":10,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"6e6d5b","input":"## Displaying the Image\n\nWe set axis to off to avoid the annoying tickmarks on the x and y axis of a pyplot plot. We then use the pyplot imshow and then show functions to show the image. We also want to view the grayscale version of the image so we do the same thing but set the image color map parameter to gray.","metadata":{"id":"2wpc7TRomH3O"},"pos":7,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"8b764d","input":"### Preprocessing the Image\n\nWe first use the io.imread() function to get the image from the url. However, we need to convert it to grayscale format because we are using the OpenCV classifier. The io image originally comes in RGB color. This is the image we will use to display the boxes around the faces. We also need to convert the image to grayscale as the OpenCV model only works on grayscale faces. \n\n","metadata":{"id":"PXRqLJQ58el8"},"pos":5,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"dd9ea6","input":"### Getting the Image and Classifier\n\nHere we will get the face detector from the OpenCV library and store it in the faceCascade library. We then put the image address/url of the image. The example url below is an image of a group of four people. If you want, you can also upload a picture of yourself to google colab and put the filepath instead of the url to run facial detection on images from your own computer. ","metadata":{"id":"6VqccN6i7k3c"},"pos":2,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e95bfa","input":"# Let's Build An AI Face Detector!\n\nIn just a couple, simple lines you will be able to build your very own face detector where you can input a image url and the face detector will draw boxes around the faces before displaying the results of **AI face detection.**\n\n### Theory Behind the Model\nFirst the face detector splits the image into multiple small sections. For each section, it first runs a series of general facial tests. The sections that pass these tests move on to the next, more specific, facial tests and the ones that don't pass are disregarded. On the sections that the face detector is unsure about, it runs more and more tests (a total of 6000) until the face detector can be positive that the section is part of a face. It is like a cascade, or waterfall, of tests which is why the face detector we use is called a cascade classifier.","metadata":{"id":"npPdoLfV6RlL"},"pos":0,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"fb78bf","input":"## Try some images of your own.\n\nThere are some other images in this folder you can experiment with, or you can use your own image to try and detect faces!\n\n","pos":14,"state":"done","type":"cell"}
{"end":1656535520545,"exec_count":18,"id":"d5208b","input":"io.imread(x)","kernel":"cv_env","output":{"0":{"ename":"HTTPError","evalue":"HTTP Error 426: Upgrade Required","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/enter/envs/cv_env/lib/python3.8/site-packages/skimage/io/_io.py:52\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fname\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m     50\u001b[0m         plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtifffile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname:\n\u001b[1;32m     53\u001b[0m     img \u001b[38;5;241m=\u001b[39m call_plugin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimread\u001b[39m\u001b[38;5;124m'\u001b[39m, fname, plugin\u001b[38;5;241m=\u001b[39mplugin, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplugin_args)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","File \u001b[0;32m~/enter/envs/cv_env/lib/python3.8/contextlib.py:113\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n","File \u001b[0;32m~/enter/envs/cv_env/lib/python3.8/site-packages/skimage/io/util.py:28\u001b[0m, in \u001b[0;36mfile_or_url_context\u001b[0;34m(resource_name)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(delete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, suffix\u001b[38;5;241m=\u001b[39mext) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 28\u001b[0m         u \u001b[38;5;241m=\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(u\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# f must be closed before yielding\u001b[39;00m\n","File \u001b[0;32m~/enter/envs/cv_env/lib/python3.8/urllib/request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/enter/envs/cv_env/lib/python3.8/urllib/request.py:531\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    530\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 531\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n","File \u001b[0;32m~/enter/envs/cv_env/lib/python3.8/urllib/request.py:640\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 640\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n","File \u001b[0;32m~/enter/envs/cv_env/lib/python3.8/urllib/request.py:569\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    568\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/enter/envs/cv_env/lib/python3.8/urllib/request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    501\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m~/enter/envs/cv_env/lib/python3.8/urllib/request.py:649\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n","\u001b[0;31mHTTPError\u001b[0m: HTTP Error 426: Upgrade Required"]}},"pos":15,"start":1656535520427,"state":"done","type":"cell"}
{"end":1656535645320,"exec_count":20,"id":"0047f9","input":"io.imread('selfie.jpg')","kernel":"cv_env","output":{"0":{"data":{"text/plain":"array([[[ 14,   2,   2],\n        [ 14,   2,   2],\n        [ 17,   7,   6],\n        ...,\n        [ 23,  34,  52],\n        [ 23,  34,  52],\n        [ 23,  34,  52]],\n\n       [[ 14,   2,   2],\n        [ 14,   2,   2],\n        [ 16,   6,   5],\n        ...,\n        [ 18,  29,  47],\n        [ 18,  29,  47],\n        [ 18,  29,  47]],\n\n       [[ 14,   4,   3],\n        [ 14,   4,   3],\n        [ 15,   5,   4],\n        ...,\n        [ 11,  19,  38],\n        [ 11,  19,  38],\n        [  9,  20,  38]],\n\n       ...,\n\n       [[116,   0,   1],\n        [116,   0,   1],\n        [117,   1,   2],\n        ...,\n        [  1,   2,   6],\n        [  1,   2,   6],\n        [  1,   2,   6]],\n\n       [[119,   0,   2],\n        [119,   0,   2],\n        [120,   1,   3],\n        ...,\n        [  1,   2,   6],\n        [  1,   2,   6],\n        [  1,   2,   6]],\n\n       [[120,   0,   2],\n        [120,   0,   2],\n        [121,   1,   3],\n        ...,\n        [  1,   2,   6],\n        [  1,   2,   6],\n        [  1,   2,   6]]], dtype=uint8)"},"exec_count":20}},"pos":2.5,"start":1656535645317,"state":"done","type":"cell"}
{"id":"b08d50","input":"","pos":17,"type":"cell"}
{"id":0,"time":1656535425505,"type":"user"}
{"last_load":1656534499446,"type":"file"}